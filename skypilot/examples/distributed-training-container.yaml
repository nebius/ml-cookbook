resources:
  infra: k8s # or infra: nebius or e.g. infra: nebius/us-central1
  accelerators: H100:8
  image_id: docker:nvcr.io/nvidia/pytorch:23.10-py3
  
num_nodes: 2

setup: |
    # Clone Pytorch examples repo
    git clone --depth 1 https://github.com/pytorch/examples || true
    cd examples
    git filter-branch --prune-empty --subdirectory-filter distributed/minGPT-ddp
    # Install dependencies
    pip install uv
    uv pip install -r requirements.txt "numpy" "torch" --system
    
run: |
    cd examples/mingpt
    export LOGLEVEL=INFO

    MASTER_ADDR=$(echo "$SKYPILOT_NODE_IPS" | head -n1)
    echo "Starting distributed training, head node: $MASTER_ADDR"

    torchrun \
    --nnodes=$SKYPILOT_NUM_NODES \
    --nproc_per_node=$SKYPILOT_NUM_GPUS_PER_NODE \
    --master_addr=$MASTER_ADDR \
    --master_port=8008 \
    --node_rank=${SKYPILOT_NODE_RANK} \
    main.py 